{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis for YELP Reviews"
      ],
      "metadata": {
        "id": "QM20kn4K2bs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this NLP project we aim to do Sentimente Analysis of YELP reviews by training a model that will detect with a good accuracy the sentiment of the reviews\n",
        "\n",
        "Sentiment is based of the star raiting of the review.\n",
        "* 4-5 = positive\n",
        "* 3 = neutral\n",
        "* 1-2 = negative"
      ],
      "metadata": {
        "id": "HdRGv_0428fT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prep"
      ],
      "metadata": {
        "id": "mRF1mQjf3unH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we prepare/load the data and the pipeline for the models"
      ],
      "metadata": {
        "id": "abHIVVN-omhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import pickle\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "BjT_v3345HVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "df = pd.read_csv(\"../DATA/yelp.csv\")"
      ],
      "metadata": {
        "id": "GRrng5V_oI3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('../MODELS/advanced', exist_ok=True)\n",
        "os.makedirs('../RESULTS/advanced', exist_ok=True)"
      ],
      "metadata": {
        "id": "1ZSY5Y1d5UXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model pipelines\n",
        "pipelines = {\n",
        "    'MultinomialNB_CountVec': Pipeline([\n",
        "        ('vectorizer', CountVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
        "        ('classifier', MultinomialNB())\n",
        "    ]),\n",
        "    'MultinomialNB_TfidfVec': Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
        "        ('classifier', MultinomialNB())\n",
        "    ]),\n",
        "    'LinearSVC_TfidfVec': Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
        "        ('classifier', LinearSVC(random_state=42))\n",
        "    ]),\n",
        "    'LogisticRegression_TfidfVec': Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
        "        ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "pVyXfYpi7DYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "ZukpXlKP48BI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create all the functions for preprocessing and feature extraction\n",
        "\n",
        "Things done:\n",
        "* Tokenization\n",
        "* Stopword Removal\n",
        "* Steeming\n",
        "* Lemmatization"
      ],
      "metadata": {
        "id": "6Jo6btujos-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation, numbers, whitespaces, and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "9hN9IY3L47Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text, nlp, remove_stopwords=True, lemmatize=True):\n",
        "    cleaned_text = clean_text(text)\n",
        "    doc = nlp(cleaned_text)\n",
        "\n",
        "    processed_tokens = []\n",
        "\n",
        "    for token in doc:\n",
        "        # Skip stopwords if requested\n",
        "        if remove_stopwords and token.is_stop:\n",
        "            continue\n",
        "        # Skip punctuation and whitespace\n",
        "        if token.is_punct or token.is_space:\n",
        "            continue\n",
        "        # Get the base form (lemma) if requested, otherwise use the original form\n",
        "        processed_token = token.lemma_ if lemmatize else token.text\n",
        "\n",
        "        processed_tokens.append(processed_token)\n",
        "\n",
        "    # Join tokens back into string\n",
        "    processed_text = ' '.join(processed_tokens)\n",
        "\n",
        "    return processed_text"
      ],
      "metadata": {
        "id": "R5jkuhKo4-Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add three classes for the target\n",
        "def convert_to_sentiment(stars):\n",
        "    if stars <= 2:\n",
        "        return 'negative'\n",
        "    elif stars == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'positive'"
      ],
      "metadata": {
        "id": "S2XcStf_5rpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_text_features(df, text_column):\n",
        "    df_features = df.copy()\n",
        "    df_features['text_length'] = df_features[text_column].apply(len)\n",
        "    df_features['word_count'] = df_features[text_column].apply(lambda x: len(x.split()))\n",
        "\n",
        "    # Add average word length feature\n",
        "    df_features['avg_word_length'] = df_features[text_column].apply(\n",
        "        lambda x: np.mean([len(word) for word in x.split()]) if len(x.split()) > 0 else 0\n",
        "    )\n",
        "\n",
        "    return df_features"
      ],
      "metadata": {
        "id": "azqxeSgl6KG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprosessing"
      ],
      "metadata": {
        "id": "U5G3GslL4sEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9A292B62QKH"
      },
      "outputs": [],
      "source": [
        "# Applying functions to the data\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "df['processed_text'] = [preprocessing(text, nlp) for text in tqdm(df['cleaned_text'])]\n",
        "df['processed_text'] = df['processed_text'].fillna('')\n",
        "df['sentiment'] = df['stars'].apply(convert_to_sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction and Models"
      ],
      "metadata": {
        "id": "E1Ziw6xr4x_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF and Bag of Words (CountVectorizer) were used\n",
        "\n",
        "Saving the best model (LinearSVC) in another folder, to ensure modularity and reusability"
      ],
      "metadata": {
        "id": "LfKj0wlzm-ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature-enhanced dataset\n",
        "df_features = add_text_features(df, 'processed_text')\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_features['processed_text'],\n",
        "    df_features['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_features['sentiment']\n",
        ")"
      ],
      "metadata": {
        "id": "EDWbipEq40Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation scores for each pipeline\n",
        "cv_results = {}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "    cv_results[name] = {\n",
        "        'scores': cv_scores,\n",
        "        'mean': cv_scores.mean(),\n",
        "        'std': cv_scores.std()\n",
        "    }\n",
        "    print(f\"{name} CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "# Find the best model from cross-validation\n",
        "best_model_name = max(cv_results, key=lambda k: cv_results[k]['mean'])\n",
        "print(f\"\\nBest model from cross-validation: {best_model_name}\")"
      ],
      "metadata": {
        "id": "WlNbDgkz6_0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for the best model\n",
        "param_grids = {\n",
        "    'MultinomialNB_CountVec': {\n",
        "        'vectorizer__max_features': [5000, 10000, 15000],\n",
        "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "        'classifier__alpha': [0.01, 0.1, 1.0]\n",
        "    },\n",
        "    'MultinomialNB_TfidfVec': {\n",
        "        'vectorizer__max_features': [5000, 10000, 15000],\n",
        "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "        'classifier__alpha': [0.01, 0.1, 1.0]\n",
        "    },\n",
        "    'LinearSVC_TfidfVec': {\n",
        "        'vectorizer__max_features': [5000, 10000, 15000],\n",
        "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
        "        'classifier__C': [0.1, 1.0, 10.0]\n",
        "    },\n",
        "    'LogisticRegression_TfidfVec': {\n",
        "        'vectorizer__max_features': [5000, 10000, 15000],\n",
        "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
        "        'classifier__C': [0.1, 1.0, 10.0]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "vBYF9kA_7UIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run grid search on the best model\n",
        "grid_search = GridSearchCV(\n",
        "    pipelines[best_model_name],\n",
        "    param_grids[best_model_name],\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_pipeline = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "0VvEQIDw7k1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on test data\n",
        "y_pred = best_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "YnkKyZb37pQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Metrics"
      ],
      "metadata": {
        "id": "yWShadas7t3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For modularity, save images and metrics to a different folder"
      ],
      "metadata": {
        "id": "OaGCMSd3nDx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Best Model')\n",
        "plt.savefig('../results/advanced/confusion_matrix_best_model.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "q5l6hvJ67rhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For vectorizer-based models\n",
        "feature_names = best_pipeline.named_steps['vectorizer'].get_feature_names_out()\n",
        "\n",
        "# For different classifier types\n",
        "if best_model_name.startswith('MultinomialNB'):\n",
        "    classifier = best_pipeline.named_steps['classifier']\n",
        "    feature_importance = classifier.feature_log_prob_[1] - classifier.feature_log_prob_[0]\n",
        "\n",
        "elif best_model_name.startswith('LinearSVC') or best_model_name.startswith('LogisticRegression'):\n",
        "    classifier = best_pipeline.named_steps['classifier']\n",
        "    feature_importance = classifier.coef_[0]\n",
        "\n",
        "else:  # Default for other models\n",
        "    feature_importance = np.zeros(len(feature_names))"
      ],
      "metadata": {
        "id": "YJeKqmpW76Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top features\n",
        "top_n = 20\n",
        "top_indices = np.argsort(feature_importance)[-top_n:]\n",
        "top_features = [(feature_names[i], feature_importance[i]) for i in top_indices]\n",
        "bottom_indices = np.argsort(feature_importance)[:top_n]\n",
        "bottom_features = [(feature_names[i], feature_importance[i]) for i in bottom_indices]"
      ],
      "metadata": {
        "id": "bdGJqb_d79-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh([f[0] for f in reversed(top_features)], [f[1] for f in reversed(top_features)])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top Positive Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/advanced/top_positive_features.png')\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh([f[0] for f in bottom_features], [f[1] for f in bottom_features])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top Negative Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/advanced/top_negative_features.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "XdHNkMsL7_pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "print(\"\\nSaving the best model...\")\n",
        "with open('../models/advanced/best_pipeline.pkl', 'wb') as f:\n",
        "    pickle.dump(best_pipeline, f)\n",
        "\n",
        "def predict_sentiment(text, pipeline=best_pipeline):\n",
        "    # Transform text to features\n",
        "    if hasattr(pipeline.named_steps['classifier'], 'predict_proba'):\n",
        "        prediction = pipeline.predict([text])[0]\n",
        "        probabilities = pipeline.predict_proba([text])[0]\n",
        "        confidence = probabilities.max()\n",
        "    else:\n",
        "        # For models without predict_proba (like LinearSVC)\n",
        "        prediction = pipeline.predict([text])[0]\n",
        "        # Use decision function as a proxy for confidence\n",
        "        decision_values = pipeline.decision_function([text])[0]\n",
        "        if isinstance(decision_values, np.ndarray):\n",
        "            confidence = abs(decision_values).max()\n",
        "        else:\n",
        "            confidence = abs(decision_values)\n",
        "\n",
        "    return {\n",
        "        'sentiment': prediction,\n",
        "        'confidence': confidence\n",
        "    }\n",
        "\n",
        "# Save the prediction function\n",
        "with open('../models/advanced/predict_function.pkl', 'wb') as f:\n",
        "    pickle.dump(predict_sentiment, f)\n",
        "\n",
        "# Test the prediction function\n",
        "print(\"\\nTesting prediction function:\")\n",
        "example_texts = [\n",
        "    \"I absolutely love this restaurant! The food is amazing and the service is excellent.\",\n",
        "    \"This place is terrible. I regret eating here. Complete waste of money.\",\n",
        "    \"It's okay, not great but not terrible either.\",\n",
        "    \"The staff was friendly and helpful, but the food was disappointing.\",\n",
        "    \"The quality is poor and the prices are too high for what you get.\"\n",
        "]\n",
        "\n",
        "for text in example_texts:\n",
        "    result = predict_sentiment(text)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Predicted sentiment: {result['sentiment']}\")\n",
        "    print(f\"Confidence: {result['confidence']:.4f}\\n\")\n",
        "\n",
        "print(\"Advanced model training and evaluation complete!\")"
      ],
      "metadata": {
        "id": "t_-Q9jNP8F8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}